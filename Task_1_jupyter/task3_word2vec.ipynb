{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "task3_word2vec.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "CfxvMHvvwRPk",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import torch\n",
    "from torch import cuda\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6DSLobGawaKO",
    "colab_type": "code",
    "outputId": "4fb7c98a-f0be-4033-9ad2-eeb9b6350f7e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "with open(r\"C:\\Users\\Andrey\\Google Диск\\DeepPavlov\\text8\",\"r\") as f:\n",
    "  data = f.read()"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3b114cd342b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\Andrey\\Google Диск\\DeepPavlov\\text8\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m   \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\Andrey\\\\Google Диск\\\\DeepPavlov\\\\text8'"
     ],
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\Andrey\\\\Google Диск\\\\DeepPavlov\\\\text8'",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uAUKgtOGTw3s",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from string import punctuation\n",
    "corpus = ''.join([c.lower() for c in data if c not in punctuation+'«»']).split()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9-4pGLGvqbdi",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# считаем слова и сортируем по убыванию количества вхождений\n",
    "def counter(words):\n",
    "  count_words = Counter(words)\n",
    "  total_words = len(words)\n",
    "  sorted_words = count_words.most_common(total_words)\n",
    "  print('total words: {}'.format(total_words))\n",
    "  print(sorted_words[150:200])\n",
    "  less_10, more_10 = 0, 0\n",
    "  for word,freq in sorted_words:\n",
    "    if freq>10:\n",
    "        more_10+=1\n",
    "    if freq<10:\n",
    "        less_10+=1\n",
    "  print('more then 10: {}, less then 10: {}'.format(more_10,less_10))\n",
    "  return sorted_words, more_10\n",
    "\n",
    "\n",
    "# назначаю каждому токену номер\n",
    "def make_dicts(sorted_words, dimensionality):\n",
    "  word2index = {w:i+1 for i, (w,c) in enumerate(sorted_words[:(dimensionality-1)])}   \n",
    "  word2index['UNK'] = 0\n",
    "  index2word = {i+1:w for i, (w,c) in enumerate(sorted_words[:(dimensionality-1)])}\n",
    "  index2word[0] = 'UNK'\n",
    "  return word2index, index2word\n",
    "\n",
    "\n",
    "class Data_Processing_CBOW():\n",
    "  def __init__(self, corpus, window_size):\n",
    "    self.corpus = corpus\n",
    "    self.window_size = window_size\n",
    "    self.dimensionality = np.nan\n",
    "\n",
    "\n",
    "  def get_data(self):\n",
    "    sorted_words, self.dimensionality = counter(self.corpus)\n",
    "    word2index, index2word = make_dicts(sorted_words, self.dimensionality)\n",
    "    # собственно делаем X,y\n",
    "    X,y = [],[]\n",
    "    num_sent = [word2index[x] if x in word2index.keys() else 0 for x in self.corpus]\n",
    "    for cur_idx,num in enumerate(num_sent[self.window_size:-self.window_size]):\n",
    "      idx = cur_idx+self.window_size\n",
    "      y.append(num)\n",
    "      X.append(num_sent[idx-self.window_size:idx]+num_sent[idx+1:idx+self.window_size+1])\n",
    "\n",
    "    return np.array(X), np.array(y), word2index, index2word"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GitgCbHbqmHy",
    "colab_type": "code",
    "outputId": "d47804e0-b0a9-4ca0-ffed-5e6785e2134d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    }
   },
   "source": [
    "X, y, word2index, index2word = Data_Processing_CBOW(corpus, 5).get_data()"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "total words: 17005207\n",
      "[('french', 8736), ('before', 8700), ('general', 8659), ('what', 8581), ('t', 8491), ('against', 8432), ('n', 8372), ('high', 8337), ('links', 8312), ('could', 8304), ('based', 8244), ('those', 8209), ('now', 8206), ('second', 8110), ('de', 8002), ('music', 7987), ('another', 7933), ('large', 7898), ('she', 7896), ('f', 7878), ('external', 7862), ('german', 7858), ('different', 7797), ('modern', 7790), ('great', 7770), ('do', 7763), ('common', 7698), ('set', 7682), ('list', 7672), ('south', 7628), ('series', 7611), ('major', 7585), ('game', 7553), ('power', 7522), ('long', 7488), ('country', 7481), ('king', 7456), ('law', 7435), ('group', 7417), ('film', 7400), ('still', 7378), ('until', 7368), ('north', 7328), ('international', 7262), ('term', 7219), ('we', 7118), ('end', 7113), ('book', 7110), ('found', 7043), ('own', 7034)]\n",
      "more then 10: 44611, less then 10: 206720\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N_NCXe_F20ak",
    "colab_type": "code",
    "outputId": "8e2838f0-55e7-475f-d11e-c278633e1cad",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "# import shutil\n",
    "# shutil.move('w2v_data.pkl', \"/content/gdrive/My Drive/DeepPavlov/w2v_data.pkl\") "
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/content/gdrive/My Drive/DeepPavlov/w2v_data.pkl'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EBnXhK5Nhcnb",
    "colab_type": "code",
    "outputId": "055cc15c-78a8-4dff-eb76-34c06caacb9f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "print(X.shape, y.shape)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "(17005197, 10) (17005197,)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bGjuR9rbrC4A",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class My_Dataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx, :], self.y[idx]\n",
    "\n",
    "\n",
    "class EarlyStopping():\n",
    "    def __init__(self, patience=5, min_percent_gain=0.1):\n",
    "        self.patience = patience\n",
    "        self.loss_list = []\n",
    "        self.min_percent_gain = min_percent_gain / 100.\n",
    "        \n",
    "    def update_loss(self, loss):\n",
    "        self.loss_list.append(loss)\n",
    "        if len(self.loss_list) > self.patience:\n",
    "            del self.loss_list[0]\n",
    "    \n",
    "    def stop_training(self):\n",
    "        if len(self.loss_list) == 1:\n",
    "            return False\n",
    "        gain = (max(self.loss_list) - min(self.loss_list)) / max(self.loss_list)\n",
    "        print(\"Loss gain: {}%\".format(round(100*gain,2)))\n",
    "        if gain < self.min_percent_gain:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    # for every Linear layer in a model\n",
    "    if classname.find('Linear') != -1:\n",
    "        y = m.in_features\n",
    "    # m.weight.data shoud be taken from a normal distribution\n",
    "        m.weight.data.normal_(0.0,1/np.sqrt(y))\n",
    "    # m.bias.data should be 0\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "    elif classname.find('Embedding') != -1:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Fa7XiPZyrTC7",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "      super().__init__()\n",
    "\n",
    "      self.emb = nn.Embedding(vocab_size, embedding_dim)\n",
    "      self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "      out = torch.sum(self.emb(x), dim=1)  # [batch_size, 2*window_size, 20000] => [batch_size, 20000]\n",
    "      out = self.linear(out)\n",
    "      # print(out.shape)\n",
    "      out = F.log_softmax(out, dim=1)\n",
    "      # print(out.shape)\n",
    "\n",
    "      return out\n",
    "\n",
    "    def word_embeddings(self, word):                          # функция для п.3 function to map token to corresponding word vector\n",
    "      word = torch.LongTensor([word2index[word]])     \n",
    "      if cuda.is_available():\n",
    "          word = word.cuda()\n",
    "      else:\n",
    "          self.cpu()\n",
    "      return self.emb(word)\n",
    "\n",
    "\n",
    "net = model(len(word2index.keys()), 300)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "86HanHD2s9yc",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print_every = 10\n",
    "num_epochs = 100\n",
    "batch_size = 512\n",
    "lr = 0.01\n",
    "\n",
    "batcher_train = DataLoader(My_Dataset(X, y), batch_size=batch_size, shuffle=False)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oMD473cqtI9C",
    "colab_type": "code",
    "outputId": "50e6f191-73bb-48a6-9e7c-14c72738ff43",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "# https://github.com/jeffchy/pytorch-word-embedding/blob/master/CBOW.py              самая толковая версия\n",
    "# https://github.com/FraLotito/pytorch-continuous-bag-of-words/blob/master/cbow.py   реализована get_embeddings\n",
    "\n",
    "\n",
    "if cuda.is_available():\n",
    "    net = net.cuda()\n",
    "\n",
    "# cбросить веса\n",
    "# net.apply(weights_init)\n",
    "\n",
    "\n",
    "train_loss=[]\n",
    "train_accuracy=[]\n",
    "\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    iter_loss = 0.0\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "\n",
    "    net.train()  # Put the network into training mode\n",
    "\n",
    "    for i, (items, classes) in tqdm(enumerate(batcher_train)):\n",
    "\n",
    "        # Convert torch tensor to Variable\n",
    "        items = Variable(torch.LongTensor(items))\n",
    "        classes = Variable(torch.LongTensor(classes))\n",
    "\n",
    "        # If we have GPU, shift the data to GPU\n",
    "        if cuda.is_available():\n",
    "            items = items.cuda()\n",
    "            classes = classes.cuda()\n",
    "\n",
    "        net.zero_grad()  # Clear off the gradients from any past operation\n",
    "        outputs = net(items)   # Do the forward pass\n",
    "\n",
    "        lr = lr / (2**(epoch // 10))\n",
    "        for param_group in optimizer.param_groups:\n",
    "          param_group['lr'] = lr\n",
    "\n",
    "\n",
    "        loss = F.nll_loss(outputs, classes)                                          \n",
    "        iter_loss += loss.item()  # Accumulate the loss\n",
    "        loss.backward()  # Calculate the gradients with help of back propagation\n",
    "        optimizer.step()  # Ask the optimizer to adjust the parameters based on the gradients\n",
    "\n",
    "        # Record the correct predictions for training data\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        \n",
    "        correct += (predicted == classes.data).sum()\n",
    "        iterations += 1\n",
    "\n",
    "    # Record the training loss\n",
    "    train_loss.append(iter_loss / iterations)\n",
    "    # Record the training accuracy\n",
    "    train_accuracy.append((100 * correct / len(batcher_train.dataset)))\n",
    "    print(100.0 * correct / len(batcher_train.dataset))                                                   \n",
    "\n",
    "\n",
    "    train_loss.append(train_loss[-1])\n",
    "    train_accuracy.append(train_accuracy[-1])\n",
    "\n",
    "    early_stopping.update_loss(train_loss[-1])\n",
    "    if early_stopping.stop_training():\n",
    "        break\n",
    "    \n",
    "    # if epoch%print_every==0:\n",
    "    print('Epoch %d/%d, Tr Loss: %.4f, Tr Accuracy: %.1f'\n",
    "          % (epoch + 1, num_epochs, train_loss[-1], train_accuracy[-1]))\n",
    "    \n",
    "\n",
    "  torch.save(net, 'net.pb')\n",
    "  files.download('net.pb') "
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tensor(9.1052, device='cuda:0')\n",
      "Epoch 1/100, Tr Loss: 8.0341, Tr Accuracy: 9.0\n",
      "tensor(9.7169, device='cuda:0')\n",
      "Loss gain: 9.43%\n",
      "Epoch 2/100, Tr Loss: 7.2763, Tr Accuracy: 9.0\n",
      "tensor(10.0751, device='cuda:0')\n",
      "Loss gain: 11.6%\n",
      "Epoch 3/100, Tr Loss: 7.1019, Tr Accuracy: 10.0\n",
      "tensor(10.3960, device='cuda:0')\n",
      "Loss gain: 12.77%\n",
      "Epoch 4/100, Tr Loss: 7.0085, Tr Accuracy: 10.0\n",
      "tensor(10.6922, device='cuda:0')\n",
      "Loss gain: 13.56%\n",
      "Epoch 5/100, Tr Loss: 6.9443, Tr Accuracy: 10.0\n",
      "tensor(10.9554, device='cuda:0')\n",
      "Loss gain: 5.24%\n",
      "Epoch 6/100, Tr Loss: 6.8948, Tr Accuracy: 10.0\n",
      "tensor(11.1890, device='cuda:0')\n",
      "Loss gain: 3.49%\n",
      "Epoch 7/100, Tr Loss: 6.8543, Tr Accuracy: 11.0\n",
      "tensor(11.3926, device='cuda:0')\n",
      "Loss gain: 2.69%\n",
      "Epoch 8/100, Tr Loss: 6.8199, Tr Accuracy: 11.0\n",
      "tensor(11.5709, device='cuda:0')\n",
      "Loss gain: 2.22%\n",
      "Epoch 9/100, Tr Loss: 6.7901, Tr Accuracy: 11.0\n",
      "tensor(11.7228, device='cuda:0')\n",
      "Loss gain: 1.9%\n",
      "Epoch 10/100, Tr Loss: 6.7639, Tr Accuracy: 11.0\n",
      "tensor(11.7972, device='cuda:0')\n",
      "Loss gain: 1.41%\n",
      "Epoch 11/100, Tr Loss: 6.7580, Tr Accuracy: 11.0\n",
      "tensor(11.7972, device='cuda:0')\n",
      "Loss gain: 0.91%\n",
      "Epoch 12/100, Tr Loss: 6.7580, Tr Accuracy: 11.0\n",
      "tensor(11.7972, device='cuda:0')\n",
      "Loss gain: 0.47%\n",
      "Epoch 13/100, Tr Loss: 6.7580, Tr Accuracy: 11.0\n",
      "tensor(11.7972, device='cuda:0')\n",
      "Loss gain: 0.09%\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "error",
     "ename": "MessageError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-bcc309ffe462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'net.pb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m   \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'net.pb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-bcc309ffe462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'net.pb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m   \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'net.pb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MZNsmCNl6Cvt",
    "colab_type": "code",
    "outputId": "4b3b1e6f-59d5-4eb1-94fd-85b3f253e213",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "# import shutil\n",
    "# shutil.move(\"net.pb\", \"/content/gdrive/My Drive/DeepPavlov/net_text8.pb\") "
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/content/gdrive/My Drive/DeepPavlov/net_text8_temp.pb'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omyvSRFansMX",
    "colab_type": "text"
   },
   "source": [
    "#Загружаем уже подсчитанную модель"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xpLSjz37x1Z0",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "e8edfff3-d7f3-47f7-a144-3406ad791fb1"
   },
   "source": [
    "net = torch.load(\"/content/gdrive/My Drive/DeepPavlov/net_text8.pb\")\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "with open(\"/content/gdrive/My Drive/DeepPavlov/w2v_data.pkl\",\"rb\") as f:\n",
    "  [X, y, word2index, index2word] = pickle.load(f) "
   ],
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3PsatQzq094d",
    "colab_type": "code",
    "outputId": "2a81cc55-e5d9-4538-fa89-ae8a436e97d6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    }
   },
   "source": [
    "print(net)"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "model(\n",
      "  (emb): Embedding(44611, 300)\n",
      "  (linear): Linear(in_features=300, out_features=44611, bias=True)\n",
      ")\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yENbGaJiXTZk",
    "colab_type": "code",
    "outputId": "58c43c52-7712-4899-b5c2-e2cdc819a0d6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "# net = net.cpu()\n",
    "# net.emb(torch.LongTensor([word2index['the']])).shape\n",
    "net.word_embeddings('the').shape"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVFPDn-W9sHM",
    "colab_type": "text"
   },
   "source": [
    "#vizualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x8RTWMANXULN",
    "colab_type": "code",
    "outputId": "4271d778-be91-4f5d-e47d-a94a818ad40a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    }
   },
   "source": [
    "# нарисую все это\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from matplotlib import pyplot as plt\n",
    "start, end = 3000, 3030\n",
    "\n",
    "df = pd.DataFrame(data=net.emb.weight.detach().numpy(), index=[index2word[x] for x in range(len(word2index))])\n",
    "\n",
    "svd = TruncatedSVD(n_components=2, algorithm='randomized', n_iter=15, random_state=None)\n",
    "M_reduced = svd.fit_transform(df.values)\n",
    "\n",
    "\n",
    "sub_words = df.iloc[start:end,:]\n",
    "types = sub_words.index\n",
    "x_coords = M_reduced[start:end,0]\n",
    "y_coords = M_reduced[start:end,1]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "for i,type in enumerate(types):\n",
    "    x = x_coords[i]\n",
    "    y = y_coords[i]\n",
    "    plt.scatter(x, y, marker='x', color='red')\n",
    "    plt.text(x+0.0003, y+0.0003, type, fontsize=9)\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAngAAAGbCAYAAABXr+2LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njyHgAQAAeMz/A2G+LYkPCWMEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRDW7cW69mZp",
    "colab_type": "text"
   },
   "source": [
    "#intrinsic test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-lHOVVS6A_Gs",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# intrinsic_test\n",
    "with open(\"/content/gdrive/My Drive/DeepPavlov/intrinsic_test.txt\",\"r\") as f:\n",
    "  intrinsic_test = f.read()\n",
    "\n",
    "intrinsic_data = [x.split() for x in intrinsic_test.split('\\n')]\n",
    "intrinsic_data = [x for x in intrinsic_data if len(x)==4]"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4qDEMj5Y-UDi",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# https://web.stanford.edu/class/cs224n/materials/Gensim%20word%20vector%20visualization.html   \n",
    "# standford gensim realization не получилось повторить \n",
    "\n",
    "# from gensim.test.utils import datapath, get_tmpfile\n",
    "# from gensim.models import KeyedVectors\n",
    "# from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# word2vec_glove_file = get_tmpfile(\"/content/gdrive/My Drive/DeepPavlov/glove.6B.100d.txt\")\n",
    "# model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
    "# model.most_similar('obama')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NUw5LJbpDy2V",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# https://programmer.group/pytorch-implements-word2vec.html                                    чувак подкинул\n",
    "# сделал кастомный вариант подсчета cosine_similarity\n",
    "def prepare_x(x):\n",
    "  if x in word2index.keys():\n",
    "      x = net.emb(torch.LongTensor([word2index[x]]))\n",
    "      if cuda.is_available():\n",
    "        x.cuda()\n",
    "  else:\n",
    "      x = 'UNK'\n",
    "  return x\n",
    "all_values=[]\n",
    "\n",
    "def cosine_similarity(data):\n",
    "    \"\"\" Returns the cosine similarity of validation words with words in the embedding matrix.\n",
    "        Here, embedding should be a PyTorch embedding module.\n",
    "    \"\"\"\n",
    "    [a_,b_,c_,d_] = data\n",
    "\n",
    "    if cuda.is_available():\n",
    "      device='cuda'\n",
    "    else:\n",
    "      device='cpu'\n",
    "\n",
    "    # Here we're calculating the cosine similarity between some random words and \n",
    "    # our embedding vectors. With the similarities, we can look at what words are\n",
    "    # close to our random words.\n",
    "    \n",
    "    # sim = (a . b) / |a||b|\n",
    "    try:\n",
    "      a,b,c,d = prepare_x(a_),prepare_x(b_),prepare_x(c_),prepare_x(d_),\n",
    "\n",
    "      summ = b-a+c\n",
    "      magn_d = d.pow(2).sum(dim=1).sqrt().unsqueeze(0)\n",
    "      magn_result = summ.pow(2).sum(dim=1).sqrt().unsqueeze(0)\n",
    "      \n",
    "      similarities = torch.mm(d, summ.t())/(magn_d*magn_result)\n",
    "\n",
    "      # print(\"{} к {} как {} к {}\".format(data[0], data[1], data[2], data[3]))\n",
    "      # print(similarities.detach().cpu().numpy()[0][0])\n",
    "      all_values.append(similarities.detach().cpu().numpy()[0][0])\n",
    "    except:\n",
    "      pass"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-uB_PRwwbHuO",
    "colab_type": "code",
    "outputId": "f7ea27c1-ef14-4059-945f-56ebb08f8dca",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "for example in intrinsic_data:\n",
    "  cosine_similarity(example)\n",
    "print('MEAN {}'.format(np.mean(all_values)))"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "MEAN 0.205417662858963\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBmDYrjZS7_-",
    "colab_type": "text"
   },
   "source": [
    "#extrinsic test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e-xzGdOqgzQZ",
    "colab_type": "code",
    "outputId": "66ba7442-02ce-411e-9d10-21e11377cee4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "# взят датасет https://www.kaggle.com/kazanova/sentiment140\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "raw = pd.read_csv(\"/content/gdrive/My Drive/DeepPavlov/sentiment140/training.1600000.processed.noemoticon.csv\",\n",
    "            sep=\",\", encoding='latin-1', header=None).loc[:,[0,5]]"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LZ4dDc0KTRBo",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "twits = []\n",
    "for row in raw[5]:\n",
    "  temp = row.split()\n",
    "  temp = ['URL' if c.startswith('http') else c for c in temp]\n",
    "  temp = ['NAME' if c.startswith('@') else c for c in temp]\n",
    "\n",
    "  # print(temp)\n",
    "  twits.append(''.join([c.lower() for c in \" \".join(temp) if c not in punctuation+'«»']).split())"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "98WEhhuJTilC",
    "colab_type": "code",
    "outputId": "2fba3b71-94ba-4715-eb69-ca18e3769ca0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    }
   },
   "source": [
    "raw[5] = twits\n",
    "raw.rename(columns={0:'target',5:'twit'}, inplace=True)\n",
    "raw.head()"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>twit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[name, url, awww, thats, a, bummer, you, shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[is, upset, that, he, cant, update, his, faceb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[name, i, dived, many, times, for, the, ball, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[name, no, its, not, behaving, at, all, im, ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               twit\n",
       "0       0  [name, url, awww, thats, a, bummer, you, shoul...\n",
       "1       0  [is, upset, that, he, cant, update, his, faceb...\n",
       "2       0  [name, i, dived, many, times, for, the, ball, ...\n",
       "3       0  [my, whole, body, feels, itchy, and, like, its...\n",
       "4       0  [name, no, its, not, behaving, at, all, im, ma..."
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 16
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xNor5n6xC2ti",
    "colab_type": "code",
    "outputId": "d6890f99-b342-46f1-f5c1-eabd2695f38a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    }
   },
   "source": [
    "twits_len = [len(twit) for twit in raw[raw['target']==4].twit]\n",
    "print(np.mean(twits_len), np.std(twits_len))\n",
    "twits_len = [len(twit) for twit in raw[raw['target']==0].twit]\n",
    "print(np.mean(twits_len), np.std(twits_len))"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "12.6207275 6.758350380880216\n",
      "13.46716625 7.024173399401595\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EsfJv4XGBn58",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "targets = raw.target.tolist()\n",
    "\n",
    "sub_twits = [twits[i] for i, l in enumerate(twits) if 6<len(l)<20]\n",
    "sub_targets = [targets[i] for i, l in enumerate(twits) if 6<len(l)<20]\n",
    "df = pd.DataFrame(columns=raw.columns, index=range(len(sub_targets)))\n",
    "df['twit'], df['target'] = sub_twits, sub_targets"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BxiWYN_YFR17",
    "colab_type": "code",
    "outputId": "11ea8580-e421-42ed-d7cb-2da6b2771938",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    }
   },
   "source": [
    "df['target'].value_counts()"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4    469343\n",
       "0    463323\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y02kWBDJIB_6",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# https://towardsdatascience.com/sentiment-analysis-using-lstm-step-by-step-50d074f09948\n",
    "# пока не доделал\n",
    "sub_twit_tokens = [[word2index[x] if x in word2index.keys() else 0 for x in twit] for twit in sub_twits]"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AWfPdTMLDlX8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "x_train = sub_twit_tokens[:int(0.8*len(sub_targets))]\n",
    "y_train = sub_targets[:int(0.8*len(sub_targets))]\n",
    "x_val = sub_twit_tokens[int(0.8*len(sub_targets)):]\n",
    "y_val = sub_targets[int(0.8*len(sub_targets)):]"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O8lCfhzRJRwH",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "e23fedc0-998b-4f72-cf69-0a25ca9725dd"
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(sub_twit_tokens, sub_targets, test_size=0.10, random_state=42, )\n",
    "np.unique(y_train, return_counts=True)"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0, 4]), array([417116, 422283]))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1660rKiXGcup",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class My_Dataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_x = np.zeros((20,1), dtype=int)\n",
    "        batch_x[:len(self.x[idx]),0] = self.x[idx]\n",
    "        \n",
    "\n",
    "        return batch_x, self.y[idx]\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "batcher_train = DataLoader(My_Dataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "batcher_val = DataLoader(My_Dataset(X_val, y_val), batch_size=batch_size, shuffle=True)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_OwroSjJDnYL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class RCNN(nn.Module):\n",
    "\tdef __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\n",
    "\t\tsuper(RCNN, self).__init__()\n",
    "\t\t\n",
    "\t\t\"\"\"\n",
    "\t\tArguments\n",
    "\t\t---------\n",
    "\t\tbatch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
    "\t\toutput_size : 2 = (pos, neg)\n",
    "\t\thidden_sie : Size of the hidden_state of the LSTM\n",
    "\t\tvocab_size : Size of the vocabulary containing unique words\n",
    "\t\tembedding_length : Embedding dimension of GloVe word embeddings\n",
    "\t\tweights : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table \n",
    "\t\t\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.output_size = output_size\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.vocab_size = vocab_size\n",
    "\t\tself.embedding_length = embedding_length\n",
    "\t\t\n",
    "\t\tself.word_embeddings = nn.Embedding(vocab_size, embedding_length)# Initializing the look-up table.\n",
    "\t\tself.word_embeddings.weight = nn.Parameter(weights, requires_grad=False) # Assigning the look-up table to the pre-trained GloVe word embedding.\n",
    "\t\tself.dropout = 0.8\n",
    "\t\tself.lstm = nn.LSTM(embedding_length, hidden_size, dropout=self.dropout, bidirectional=True)\n",
    "\t\tself.W2 = nn.Linear(2*hidden_size+embedding_length, hidden_size)\n",
    "\t\tself.label = nn.Linear(hidden_size, output_size)\n",
    "\t\t\n",
    "\tdef forward(self, input_sentence, batch_size=None):\n",
    "\t\n",
    "\t\t\"\"\" \n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tinput_sentence: input_sentence of shape = (batch_size, num_sequences)\n",
    "\t\tbatch_size : default = None. Used only for prediction on a single sentence after training (batch_size = 1)\n",
    "\t\t\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tOutput of the linear layer containing logits for positive & negative class which receives its input as the final_hidden_state of the LSTM\n",
    "\t\tfinal_output.shape = (batch_size, output_size)\n",
    "\t\t\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\tThe idea of the paper \"Recurrent Convolutional Neural Networks for Text Classification\" is that we pass the embedding vector\n",
    "\t\tof the text sequences through a bidirectional LSTM and then for each sequence, our final embedding vector is the concatenation of \n",
    "\t\tits own GloVe embedding and the left and right contextual embedding which in bidirectional LSTM is same as the corresponding hidden\n",
    "\t\tstate. This final embedding is passed through a linear layer which maps this long concatenated encoding vector back to the hidden_size\n",
    "\t\tvector. After this step, we use a max pooling layer across all sequences of texts. This converts any varying length text into a fixed\n",
    "\t\tdimension tensor of size (batch_size, hidden_size) and finally we map this to the output layer.\n",
    "\t\t\"\"\"\n",
    "\t\tinput = self.word_embeddings(input_sentence) # embedded input of shape = (batch_size, num_sequences, embedding_length)\n",
    "\t\tinput = input.permute(1, 0, 2) # input.size() = (num_sequences, batch_size, embedding_length)\n",
    "\t\tif batch_size is None:\n",
    "\t\t\th_0 = Variable(torch.zeros(2, self.batch_size, self.hidden_size).cuda()) # Initial hidden state of the LSTM\n",
    "\t\t\tc_0 = Variable(torch.zeros(2, self.batch_size, self.hidden_size).cuda()) # Initial cell state of the LSTM\n",
    "\t\telse:\n",
    "\t\t\th_0 = Variable(torch.zeros(2, batch_size, self.hidden_size).cuda())\n",
    "\t\t\tc_0 = Variable(torch.zeros(2, batch_size, self.hidden_size).cuda())\n",
    "\n",
    "\t\toutput, (final_hidden_state, final_cell_state) = self.lstm(input, (h_0, c_0))\n",
    "\t\t\n",
    "\t\tfinal_encoding = torch.cat((output, input), 2).permute(1, 0, 2)\n",
    "\t\ty = self.W2(final_encoding) # y.size() = (batch_size, num_sequences, hidden_size)\n",
    "\t\ty = y.permute(0, 2, 1) # y.size() = (batch_size, hidden_size, num_sequences)\n",
    "\t\ty = F.max_pool1d(y, y.size()[2]) # y.size() = (batch_size, hidden_size, 1)\n",
    "\t\ty = y.squeeze(2)\n",
    "\t\tlogits = self.label(y)\n",
    "\t\t\n",
    "\t\treturn logits"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NinlmNujHQkb",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "outputId": "9142b9b1-0b99-4a96-9dd0-73ed1a6efa21"
   },
   "source": [
    "net2 = RCNN(batch_size, 2, 300, len(word2index), 300, net.emb.weight )\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "train_fscore = []\n",
    "valid_fscore = []\n",
    "\n",
    "if cuda.is_available():\n",
    "    net2 = net2.cuda()\n",
    "\n",
    "# Our loss function\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    ############################\n",
    "    # Train\n",
    "    ############################\n",
    "\n",
    "    iter_loss = 0.0\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "    f_scores= 0\n",
    "\n",
    "    net2.train()  # Put the network into training mode\n",
    "\n",
    "    for i, (items, classes) in enumerate(batcher_train):\n",
    "\n",
    "        # Convert torch tensor to Variable\n",
    "        items = Variable(items)\n",
    "        classes = Variable(classes)\n",
    "\n",
    "        # If we have GPU, shift the data to GPU\n",
    "        if cuda.is_available():\n",
    "            items = items.cuda()\n",
    "            classes = classes.cuda()\n",
    "\n",
    "        optimizer.zero_grad()  # Clear off the gradients from any past operation\n",
    "        outputs = net2(items)  # Do the forward pass\n",
    "        loss = criterion(outputs, classes.long())                                               # Calculate the loss\n",
    "        iter_loss += loss.item()  # Accumulate the loss\n",
    "        loss.backward()  # Calculate the gradients with help of back propagation\n",
    "        optimizer.step()  # Ask the optimizer to adjust the parameters based on the gradients\n",
    "        print(loss.data)\n",
    "        # Record the correct predictions for training data\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == classes.data.long()).sum()\n",
    "\n",
    "        f_scores += f1_score(predicted.cpu().numpy(), classes.data.cpu().numpy(), average='macro')\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    # Record the training loss\n",
    "    train_loss.append(iter_loss / iterations)\n",
    "    # Record the training accuracy\n",
    "    train_accuracy.append((100 * correct / len(batcher_train.dataset)))\n",
    "    train_fscore.append(f_scores/iterations)\n",
    "    # print(100.0 * correct / len(batcher_train.dataset))                                                   рень с перестановкой множителей местами!\n",
    "\n",
    "    ############################\n",
    "    # Validate - How did we do on the unseen dataset?\n",
    "    ############################\n",
    "\n",
    "\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "    f_scores = 0\n",
    "\n",
    "    net2.eval()  # Put the network into evaluate mode\n",
    "\n",
    "    for i, (items, classes) in enumerate(batcher_val):\n",
    "\n",
    "        # Convert torch tensor to Variable\n",
    "        items = Variable(items)\n",
    "        classes = Variable(classes)\n",
    "\n",
    "        # If we have GPU, shift the data to GPU\n",
    "        if cuda.is_available():\n",
    "            items = items.cuda()\n",
    "            classes = classes.cuda()\n",
    "\n",
    "        outputs = net2(items)  # Do the forward pass\n",
    "        loss += criterion(outputs, classes.long()).item()  # Calculate the loss\n",
    "                                                                        # loss = criterion(outputs, classes.long()).sum()\n",
    "        # Record the correct predictions for training data\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == classes.data.long()).sum()\n",
    "\n",
    "        f_scores += f1_score(predicted.cpu().numpy(), classes.data.cpu().numpy(), average='macro')\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    # Record the validation loss\n",
    "    valid_loss.append(loss / iterations)\n",
    "    # Record the validation accuracy\n",
    "    valid_accuracy.append(100.0 * correct / float(len(batcher_val.dataset)))\n",
    "    valid_fscore.append(f_scores/iterations)\n",
    "\n",
    "    # print(correct, float(len(batcher_val.dataset)))\n",
    "    # print(100 * correct / float(len(batcher_val.dataset)))\n",
    "\n",
    "\n",
    "    print('Epoch %d/%d, Tr Loss: %.4f, Tr Fscore: %.4f, Val Loss: %.4f, Val Fscore: %.4f'\n",
    "          % (epoch + 1, config.num_epochs, train_loss[-1], train_fscore[-1],\n",
    "              valid_loss[-1], valid_fscore[-1]))"
   ],
   "execution_count": 74,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-5c586a708ae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Clear off the gradients from any past operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Do the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m                                               \u001b[0;31m# Calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0miter_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Accumulate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-0bd34f7f68d4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_sentence, batch_size)\u001b[0m\n\u001b[1;32m     53\u001b[0m \t\t\"\"\"\n\u001b[1;32m     54\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# embedded input of shape = (batch_size, num_sequences, embedding_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# input.size() = (num_sequences, batch_size, embedding_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                         \u001b[0mh_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Initial hidden state of the LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: number of dims don't match in permute"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_4tR04MsLdFR",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}